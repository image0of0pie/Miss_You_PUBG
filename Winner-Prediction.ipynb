{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-06T13:06:23.193781Z",
     "iopub.status.busy": "2021-02-06T13:06:23.192942Z",
     "iopub.status.idle": "2021-02-06T13:06:23.936693Z",
     "shell.execute_reply": "2021-02-06T13:06:23.935277Z"
    },
    "papermill": {
     "duration": 0.760483,
     "end_time": "2021-02-06T13:06:23.936924",
     "exception": false,
     "start_time": "2021-02-06T13:06:23.176441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import gc,os,sys\n",
    "%config Completer.use_jedi = False\n",
    "gc.enable()\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "# model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:06:23.967375Z",
     "iopub.status.busy": "2021-02-06T13:06:23.965167Z",
     "iopub.status.idle": "2021-02-06T13:06:23.968129Z",
     "shell.execute_reply": "2021-02-06T13:06:23.968635Z"
    },
    "papermill": {
     "duration": 0.025352,
     "end_time": "2021-02-06T13:06:23.968798",
     "exception": false,
     "start_time": "2021-02-06T13:06:23.943446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem/(1024*1024*8)))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem/(1024*1024*8)))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:06:24.088443Z",
     "iopub.status.busy": "2021-02-06T13:06:23.988891Z",
     "iopub.status.idle": "2021-02-06T13:06:24.091321Z",
     "shell.execute_reply": "2021-02-06T13:06:24.090774Z"
    },
    "papermill": {
     "duration": 0.116747,
     "end_time": "2021-02-06T13:06:24.091472",
     "exception": false,
     "start_time": "2021-02-06T13:06:23.974725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(is_train=True,debug=True):\n",
    "    test_idx = None\n",
    "    if is_train: \n",
    "        print(\"processing train.csv\")\n",
    "        if debug == True:\n",
    "            df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv', nrows=500000)\n",
    "        else:\n",
    "            df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')           \n",
    "\n",
    "        df = df[df['maxPlace'] > 1]\n",
    "    else:\n",
    "        print(\"processing test.csv\")\n",
    "        df = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n",
    "        test_idx = df.Id\n",
    "    \n",
    "    print(\"remove some columns\")\n",
    "    target = 'winPlacePerc'\n",
    "\n",
    "    print(\"Adding Features\")\n",
    " \n",
    "    df['headshotrate'] = df['kills']/df['headshotKills']\n",
    "    df['killStreakrate'] = df['killStreaks']/df['kills']\n",
    "    df['healthitems'] = df['heals'] + df['boosts']\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n",
    "    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n",
    "    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n",
    "    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n",
    "    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n",
    "    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n",
    "    df[\"skill\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n",
    "\n",
    "    df[df == np.Inf] = np.NaN\n",
    "    df[df == np.NINF] = np.NaN\n",
    "    \n",
    "    print(\"Removing Na's From DF\")\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    \n",
    "    features = list(df.columns)\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchType\")\n",
    "\n",
    "    y = None\n",
    "    \n",
    "    if is_train: \n",
    "        print(\"get target\")\n",
    "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
    "        features.remove(target)\n",
    "\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    else: df_out = df[['matchId','groupId']]\n",
    "\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    \n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    \n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "\n",
    "    X = df_out\n",
    "    \n",
    "    feature_names = list(df_out.columns)\n",
    "\n",
    "    del df, df_out, agg, agg_rank\n",
    "    gc.collect()\n",
    "\n",
    "    return X, y, feature_names, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:06:24.110237Z",
     "iopub.status.busy": "2021-02-06T13:06:24.109507Z",
     "iopub.status.idle": "2021-02-06T13:10:44.569981Z",
     "shell.execute_reply": "2021-02-06T13:10:44.570531Z"
    },
    "papermill": {
     "duration": 260.472883,
     "end_time": "2021-02-06T13:10:44.570745",
     "exception": false,
     "start_time": "2021-02-06T13:06:24.097862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train.csv\n",
      "remove some columns\n",
      "Adding Features\n",
      "Removing Na's From DF\n",
      "get target\n",
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n",
      "processing test.csv\n",
      "remove some columns\n",
      "Adding Features\n",
      "Removing Na's From DF\n",
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n",
      "Memory usage of dataframe is 105.14 MB\n",
      "Memory usage after optimization is: 24.80 MB\n",
      "Decreased by 76.4%\n",
      "Memory usage of dataframe is 457.45 MB\n",
      "Memory usage after optimization is: 107.68 MB\n",
      "Decreased by 76.5%\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,features,_=feature_engineering(True,True)\n",
    "x_test,_,_,test_idx=feature_engineering(False)\n",
    "\n",
    "x_train = reduce_mem_usage(x_train)\n",
    "x_test = reduce_mem_usage(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T13:10:44.620060Z",
     "iopub.status.busy": "2021-02-06T13:10:44.618526Z",
     "iopub.status.idle": "2021-02-06T14:27:38.639375Z",
     "shell.execute_reply": "2021-02-06T14:27:38.639964Z"
    },
    "papermill": {
     "duration": 4614.054591,
     "end_time": "2021-02-06T14:27:38.640153",
     "exception": false,
     "start_time": "2021-02-06T13:10:44.585562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 220.05054731\n",
      "Iteration 2, loss = 20.43715041\n",
      "Iteration 3, loss = 10.12497792\n",
      "Iteration 4, loss = 3.08995728\n",
      "Iteration 5, loss = 1.09281104\n",
      "Iteration 6, loss = 0.26260688\n",
      "Iteration 7, loss = 0.04315364\n",
      "Iteration 8, loss = 0.00872168\n",
      "Iteration 9, loss = 0.00733503\n",
      "Iteration 10, loss = 0.03052725\n",
      "Iteration 11, loss = 0.00735341\n",
      "Iteration 12, loss = 0.00685899\n",
      "Iteration 13, loss = 0.00673960\n",
      "Iteration 14, loss = 0.00682877\n",
      "Iteration 15, loss = 0.00669535\n",
      "Iteration 16, loss = 0.00669067\n",
      "Iteration 17, loss = 0.00667650\n",
      "Iteration 18, loss = 0.00666844\n",
      "Iteration 19, loss = 0.00664540\n",
      "Iteration 20, loss = 0.00664795\n",
      "Iteration 21, loss = 0.00667462\n",
      "Iteration 22, loss = 0.00667933\n",
      "Iteration 23, loss = 0.00662129\n",
      "Iteration 24, loss = 0.00662948\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "def trainRegressor(x_train,y_train):\n",
    "    model=MLPRegressor(random_state=1, max_iter=500,batch_size=50,learning_rate=\"adaptive\",verbose=True,validation_fraction=0.2)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model\n",
    "model = trainRegressor(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T14:27:38.693442Z",
     "iopub.status.busy": "2021-02-06T14:27:38.692629Z",
     "iopub.status.idle": "2021-02-06T14:27:38.696074Z",
     "shell.execute_reply": "2021-02-06T14:27:38.696636Z"
    },
    "papermill": {
     "duration": 0.032702,
     "end_time": "2021-02-06T14:27:38.696810",
     "exception": false,
     "start_time": "2021-02-06T14:27:38.664108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho gaya bro\n"
     ]
    }
   ],
   "source": [
    "print(\"Ho gaya bro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4881.902923,
   "end_time": "2021-02-06T14:27:39.531484",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-06T13:06:17.628561",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
